# Хэширование

**Хеширование** - это отображение некоторого множества объектов в множество чисел. Данная техника используется в хэш
таблице, которая использует хэш значение ключа для доступа к нужному бакету. Более того, хэширование позволяет
унифицировать способ доступа к произвольным данным.

# Хэш-таблица

Для начала рассмотрим структуру данных хэш-таблицу, которая по сути является синонимом хеширования.

## Описание

**Хэш-таблица (Hash table, hash map)** - это структура данных, имплементирующая интерфейс ассоциативного массива (мапы)
и позволяющая маппить ключ к значению.

Особенность хэш-таблицы в том, что в среднем случае она поддерживает доступ к ключу за константное время.

## Имплементация

Ключевая идея хэш-таблицы заключается в двух вещах:

- Использование массива для хранения пар (bucket array)
- Хэширование

Элементы массива называются бакетами (bucket). Хэш-функция используется для распределения пар в массиве бакетов (bucket
array).

Имея ключ, индекс бакета вычисляется следующим образом:

```
hash = hashfunc(key)
index = hash % array_size
```

Последнее выражение, взятие хэша по модулю размера массива, требуется потому, что хэш функция может выдать значение за
пределами массива. Такое значение замапить невозможно, если только не выделить массив такого размера, что он покрыл бы
все возможные выходные значения хеш функции. Понятно, что выделять массив такого размера совершенно не эффективно,
поэтому самым тривиальным решением остается взять хэш по модулю N, где N - размер массива.

Таким образом, имея ключ и хэш-функцию, мы можем вычислить индекс для расположения пары в нужной ячейке массива бакетов
и дальнейшего доступа к ней.

## Разрешение коллизий

При использовании хэш функций обязательно возникают *коллизии*. Коллизия хэш-функции - это случай, когда для двух
различных блоков данных мы получаем один и тот хэш или индекс. Это плохо, так как при попытке вставить новую пару, мы
можем наткнуться на уже существующую.

Решается эта проблема разными способами. Но перед тем, как перейти к этим способам, нужно рассказать об *открытом* и
*закрытом* хешировании.

## Open Hashing

**Открытое хеширование (open hashing)** - это когда элемент хранится не прямо в ячейке, указанном хэш значением, а в
списке.

Также это называется **Closed addressing** - это когда адрес (location) элемента определяется полностью лишь одним хэш
значением ключа.

Почему же эти два понятия так отличаются: в одном open, в другом closed? Дело в том, что *open* означает, что у нас нет
строгих гарантий на что-либо, а *closed* наоборот - означает что строгие гарантии есть.

То есть, open hashing - потому что объекты на самом деле не хранятся в массиве напрямую, а хранятся они в списке. Но
closed addressing потому, что адрес бакета определяется строго значением хэша.

### Separate Chaining

**Метод цепочек (separate chaining)** - это вид открытого хеширования. Он подразумевает хранение не единственной пары в
бакете, а списка пар. В качестве структуры данных обычно используется односвязный список, но может быть и Binary Search
Tree, если элементов слишком много и линейный поиск может занять много времени.

При поиске значения мы находим нужный бакет, как и раньше, а затем просто проходимся по всем парам в списке и сравниваем
искомый ключ с ключом в каждой паре, т.е. нужно, чтобы была корректно определена операция `equals`. Как только нашли
ключ, возвращаем эту пару.

При вставке же новой пары с таким же индексом мы просто добавляем эту пару в конец списка.

Понятно, что время для нахождения нужной пары увеличивается до времени нахождения ячейки массива (константное) + времени
нахождения ключа в списке.

## Closed Hashing

**Закрытое хеширование (closed hashing)** - это парадигма разрешения коллизий, которая использует *
probing* для нахождения следующей свободной ячейки массива.

Этот метод также известен как *Open addressing*, потому что здесь индекс бакета не определяется строго хэш значением, а
зависит от данных в таблице. Но closed hashing потому, что мы не выходим за рамки хеш таблицы - все элементы напрямую
хранятся в бакетах, а не списках.

Варианты разрешения коллизий типа closed hashing:

- Linear Probing
- Quadratic Probing
- Double Hashing
- и другие

Здесь можно почитать и о методе цепочек, и о других closed hashing методах разрешения
коллизий https://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B0%D0%B7%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BA%D0%BE%D0%BB%D0%BB%D0%B8%D0%B7%D0%B8%D0%B9

### Linear Probing

Если случается коллизия, т.е. ячейка с индексом i занята, то мы ищем следующую ячейку массива следующим образом:
*i + 1, i + 2, i + 3...*. Эта последовательность перебора называется *Probe sequence*.

Однако, существует проблема: такой метод создает длинные последовательности занятых бакетов. Когда мы будем добавлять
новые ключи, велик шанс, что мы попадем в одну из ячеек последовательности и еще более усугубим проблему, удлинив эту
последовательность. Все это влечет за собой увеличение среднего времени поиска и вставки. Этот феномен
называется *[Primary clustering](https://en.wikipedia.org/wiki/Primary_clustering)*.

Этот вариант обладает хорошей утилизацией кэша, но страдает от clustering.

### Quadratic Probing

Если случается коллизия, т.е. ячейка с индексом i занята, то мы ищем следующую ячейку массива следующим образом:
*i + 1^2, i + 2^2, i + 3^2...*

Такой способ оставляет большие свободные промежутки между занятыми ячейками и избегает primary clustering.

Однако, если два ключа мапятся в один и тот же индекс, то второй ключ пойдет по тем же самым шагам, что и первый ключ.
Если это происходит слишком часто (из-за плохой хеш функции), то длинные последовательности все равно образуются и
производительность падает. Да, в этом варианте сложнее попасть в индекс занятой последовательности, так как элементы
идут не подряд, но это все равно может случиться. Этот феномен называется *Secondary Clustering*, и он является
обобщением Primary Clustering.

Clustering происходит потому, что probe sequence не зависит от ключа - мы просто перебираем 1, 2, 3.., поэтому другие
элементы могут пойти по этой же последовательности. Поэтому наверняка должен быть лучший способ - и он есть, давайте
рассмотрим далее.

Этот вариант не обладает такой хорошей утилизацией кеша, как Linear Probing, но и меньше страдает от clustering.

### Double hashing

Самый продвинутый вариант. В этом методе разрешения коллизий используется еще одна хеш функция для определения probe
sequence. Допустим, мы замапили ключ в индекс i, а вторая хеш функция дает результат h2(key)=j, то последовательность
будет следующей: `i + 1*j, i + 2*j, i + 3*j`.

Этот вариант совсем плох в плане утилизации кеша, но зато избегает как primary, так и secondary clustering.

## Сравнение Open vs Closed Hashing

1. Максимально возможный Load Factor: open - бесконечный, closed - 1, потому что в closed hashing мы храним элементы
   напрямую в ячейках массива
2. Размер внутреннего массива у Closed Hashing должен быть сильно больше
3. Утилизация кеша в closed hashing лучше, так как элементы лежат линейно в памяти
4. Closed hashing работает лучше, если набор исходных элементов известен заранее
5. Clustering отсутсвует у обоих, если в closed hashing использовать double hashing.

## Идеальная хэш-функция

Когда набор значений, которые требуется замапить, известен заранее, мы можем использовать *идеальную хэш-функцию*.

**Идеальная хэш-функция (Perfect Hash Function)** - это такая хеш-функция, которая преобразует заранее известное
статическое множество ключей в диапазон целых чисел без коллизий, т.е. один ключ соответствует только одному уникальному
значению. А если количество результирующих значений такое же как и количество входящих ключей, такая функция
называется *минимальной идеальной хеш-функцией (minimal perfect hash function)*. С математической точки зрения такая
функция является *инъекцией (injection)*.

Использование идеальной хэш-функции позволяет нам:

- Добиться константного времени доступа в худшем случае, так как список больше не нужен
- Оптимизировать расходы на память, позволяя не хранить ключ, так как нам больше нет необходимости его сравнивать при
  коллизиях, так как коллизий то больше и нет

## Load Factor

**Load Factor** - это отношение количества пар, помещенных в хэш-таблицу, к количеству бакетов внутреннего массива (
размеру массива).

С возрастанием данной величины возрастает и количество коллизий, так как остается все меньше свободных бакетов, а при
превышении значения в 1 свободных бакетов совсем не остается, а значит возрастает и среднее время доступа, переставая
быть константным. Обычно, при невысоких требованиях доступности (reliability), решением является увеличение размера
таблицы в 2 раза при достижении некоторого load factor. В таком случае нам также требуется перераспределить все пары (
рехешировать).

## Анализ сложности

Проанализируем время выполнения операций и занимаемое хэш-таблицой место.

Место, занимаемое хэш-таблицей всегда зависит от количества записей - поэтому O(n).

Средний случай - это когда load factor не высокий, коллизий мало и в среднем в каждом бакете находится только по одной
паре

- **Поиск:** O(1) - требуется обратиться только к ячейке массива, что всегда происходит за константное время
- **Вставка:** O(1) - вставить новый элемент в пустой список
- **Обновление:** O(1) - найти элемент в списке из 1 пары и обновить в нем значение
- **Удаление:** O(1) - требуется обратиться к ячейке массива + удаление элемента из списка размером 1

Худший случай - это когда все элементы мапятся только в один бакет из-за плохой хэш-функции. Тогда:

- **Поиск:** O(N) - необходимо пройтись по всему списку
- **Вставка:** O(1) - требуется обратиться к ячейке массива + вставить новый элемент в конец списка
- **Обновление:** O(N) - необходимо пройти по всему массиву за O(n) + заменить значение в паре за O(1)
- **Удаление:** O(1) - необходимо пройтись по всему списку + удалить элемент. Удаление в односвязном списке - это O(1),
  но если используется другая структура данных, нужно смотреть на ее время удаления. Однако, ассимптотически операция
  удаления все равно будет работать за O(n), так как я еще не встречал такой структуры данных, удаление из которой
  заняло бы больше чем линейное время, а поиск O(n) + удаление O(n) = O(n)

---

# Консистентное хеширование

Когда мы работаем с мапами, у нас есть одна проблема - рехеширование.

## Рехеширование

Однако, здесь есть проблема: при изменении количества бакетов потребуется *рехешировать* почти все ключи, то есть
переместить их в новые ячейки с учетом изменившегося размера хеш-таблицы, если это необходимо.

# № Консистентное хеширование

Консистентное хеширование позволяет нам распределять ключи так, что при изменении количества бакетов будет рехешировано
в среднем только K/N ключей, где K - количество ключей в мапе, а N - количество бакетов после изменения. Для сравнения,
в большинстве стандартных имплементаций хеш-таблиц требуется рехешировать почти все ключи.

## Консистентное хеширование

Вот мы и подошли к главной теме статьи. Консистентное хеширование позволяет нам при изменении размера бакетов
рехешировать только K/N ключей в среднем, где K - количество ключей, а N - количество бакетов. Консистентное хеширование
не зависит напрямую от количества серверов.

Консистетное хеширование - это класс функций, обладающих вышеописанным свойством, но самый популярный алгоритм - это
консистентное хеширование на основе Hash Ring.

Идея данного алгоритма заключается в том, чтобы сравнивать сервера и ключи. Для этого каждому серверу также назначается
хэш значение с помощью той же самой хеш функции.

Далее берется окружность, на которой располагают получившиеся хеш значения серверов. На этой окружности может быть
расположено 0...2^32-1 значений, то есть размер выходного значения хеш функции (по сути, Integer). Новые ключи также
попадают на эту окружность и для них находится ближайший сервер, двигаясь по окружности. Нахождение ближайшего сервера
возможно путем сравнения хеш значений ключа и сервера.

![Consistent Hashing](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Consistent_hashing.pdf/page1-800px-Consistent_hashing.pdf.jpg)

При выходе какого либо сервера из строя потребуется перехешировать только те ключи, которые мапились в данный сервер.
При этом, новым их сервером станет тот, который следовал за старым. При добавлении же нового сервера также потребуется
перехешировать только те ключи, которые стали ближе к данному добавленному серверу, чем к тому, на который они мапились
раннее.

## Вес серверов

Чтобы распределить нагрузку с учетом мощности серверов, мы можем задать вес серверов. Имплементируется это с помощью так
называемых *Virtual Nodes*. Это сервера, которые существуют на Hash Ring только виртуально, и любой маппинг в них
отображается в действительный сервер.

При использовании виртуальных серверов на окружности размещается не один сервер, а количество, равное весу сервера.
Тогда для более мощного сервера в него будет мапиться большее количество ключей.

При удалении сервера, должны будут быть также удалены все виртуальные сервера.
