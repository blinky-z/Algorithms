# Master Theorem

## Описание

**Мастер Теорема** позволяет нам определить сложность Divide-and-Conquer алгоритмов.

Формула мастер теоремы определяет Divide-and-Conquer алгоритмы следующим образом:

```
T(n) = aT(n/b) + f(n),
где,
n = размер входных данных
a = количество подзадач, на которое мы разделяем текущую задачу на каждом вызове рекурсии
b = коэффциент, на который уменьшается размер задачи на каждом вызове рекурсии
f(n) = сложность работы, которая совершается в теле функции для текущей подзадачи. Включает в себя
сложность как разделения (divide), так и слияния результатов подзадач (conquer)

Здесь, a ≥ 1 и b > 1 - константы
```

## Вычисление сложности

Определив алгоритм через рекуррентную формулу, мы можем вычислить его сложность работы. Вообще, любой Divide-and-Conquer
алгоритм сводится к 3 случаям:

На последнем уровне дерева вызовов, которое является perfect binary tree, ровно n листьев.

1. С каждым уровнем дерева вызовов количество рекурсивных вызовов растет быстрее, чем уменьшается размер работы, то есть
   сложность решения подзадач на каждом уровне увеличивается, поэтому общая работа определяется работой на последнем
   уровне дерева, отсюда сложность функции T(n) равна `O(n^(log_b(a)))`, то есть количеству подзадач на последнем уровне
   дерева. При этом, работа для этих задач не учитывается, потому что на последнем уровне дерева вызовов, то есть
   листьях, мы дошли до базового кейса, где работа всегда должна быть константная по определению Divide-and-Conquer
   алгоритма
2. С каждым уровнем дерева вызовов количество рекурсивных вызовов растет пропорционально уменьшению размера работы, то
   есть сложность решения подзадач на каждом уровне остается одинаковым, поэтому общая работа равна f(n) помноженному на
   количество уровней дерева, отсюда сложность функции T(n) равна `O(f(n) * log n)`
3. С каждым уровнем дерева вызовов количество рекурсивных вызовов растет медленнее, чем уменьшается размер работы, то
   есть сложность решения подзадач на каждом уменьшается, уровне общая работа определяется работой на верхнем уровне
   дерева, поэтому сложность функции T(n) равна `O(f(n))`

## Примеры применения теоремы

### Binary Search

Бинарный поиск можно выразить следующей рекуррентной формулой: `T(n) = T(n/2) + O(1)`, где N - количество элементов в
массиве.

Здесь:

- `a=1`, так как алгоритм порождает только одну подзадачу: поиск элемента в левой или правой части массива
- `b=2`, так как размер подзадач каждый раз сокращается вдвое, так как мы разделяем массив на две части
- `f(n) = O(1)`, так как вся работа, которую мы делаем на подзадаче - вычисление mid индекса + сравнение, что занимает
  константное время

Здесь на каждом уровне дерева вызовов работа остается константной, так как на каждом уровне мы имеем всегда 1 подзадачу,
где делается константная работа, что сводится к 2 кейсу теоремы, поэтому сложность
равна: `T(n)=O(f(n) * log n)=O(1) * O(log n) = O(log n)`.

### Binary Tree Traversal

Обход двоичного дерева можно выразить так: `T(n) = 2T(n/2) + O(1)`, где N - это количество нод дерева.

Здесь:

- `a=2`, так как алгоритм порождает две подзадачи: обход левого и правого поддеревьев
- `b=2`, так как размер подзадач каждый раз сокращается вдвое, ведь вызывая обход на левом или правом поддереве, мы
  сокращаем количество нод, которое нужно обойти, в 2 раза. То есть, для дерева с N элементов N/2 элементов находятся в
  левом поддерева, а остальные N/2 - в правом
- `f(n) = O(1)`, так как вся работа, которую мы делаем на подзадаче - это чтение ключа текущей ноды

Здесь количество вызовов растет быстрее, чем уменьшается работа (она остается константной), поэтому сложность алгоритма
определяется работой на последнем уровне, что равно `T(n)=O(n)`.

### Merge Sort

Merge Sort можно выразить так: `T(n)=2T(n/2) + O(n)`, где N - размер массива.

Здесь:

- `a=2`, так как алгоритм порождает две подзадачи: merge sort левой и правой части массива
- `b=2`, так как мы разделяем массив на 2 равные части
- `f(n) = O(n)`, так как нам нужно разделить массив на 2 части O(1) + слить отсортированные подмассивы в один:
  скопировать подмассивы, пройтись по ним, и положить элементы в результирующий массива, что займет O(n), поэтому работа
  на каждом уровне равна O(n)

Здесь на каждом уровне дерева вызовов мы имеем одинаковую работу, так как количество вызовов растет пропорционально
уменьшению работы, что сводится к 2 кейсу теоремы и сложность равна: `T(n)=O(f(n) * log n)=O(n * log n)`.